{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8d7b17-af50-42cd-b531-ef61c49c9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Directory Path: /home/cloud/wxz/neuralangelo\n"
     ]
    }
   ],
   "source": [
    "# Set the work directory to the imaginaire root.\n",
    "import os, sys, time\n",
    "import pathlib\n",
    "root_dir = pathlib.Path().absolute().parents[2]\n",
    "os.chdir(root_dir)\n",
    "print(f\"Root Directory Path: {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5b9e2f-841c-4815-92e0-0c76ed46da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries.\n",
    "import numpy as np\n",
    "import torch\n",
    "import k3d\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "# Import imaginaire modules.\n",
    "from projects.nerf.utils import camera, visualize\n",
    "from third_party.colmap.scripts.python.read_write_model import read_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe6ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def gen_rot_view(elev, max_angle, distance, size, axis=[0, 1, 0]):\n",
    "\n",
    "#     # bg_to_cam\n",
    "\n",
    "#     cam_traj = get_rotating_cam(size, distance=distance, axis=axis, max_angle=max_angle)\n",
    "#     cam_elev = get_object_to_camera_matrix(elev, axis, 0)[None]\n",
    "#     cam_traj = cam_traj @ cam_elev\n",
    "#     # # field2cam = create_field2cam(cam_traj, field2cam_fr.keys())\n",
    "\n",
    "#     # camera_int = np.zeros((len(frameid_sub), 4))\n",
    "\n",
    "#     # # focal length = img height * distance / obj height\n",
    "#     # camera_int[:, :2] = opts[\"render_res\"] * 2 * 0.8  # zoom out a bit\n",
    "#     # camera_int[:, 2:] = opts[\"render_res\"] / 2\n",
    "#     return cam_traj\n",
    "\n",
    "# def get_rotating_cam(num_cameras, axis=[0, 1, 0], distance=3, initial_angle=0, max_angle=360):\n",
    "#     \"\"\"Generate camera sequence rotating around a fixed object\n",
    "\n",
    "#     Args:\n",
    "#         num_cameras (int): Number of cameras in sequence\n",
    "#         axis (ndarray): (3,) Axis of rotation\n",
    "#         distance (float): Distance from camera to object\n",
    "#         initial_angle (float): Initial rotation angle, degrees (default 0)\n",
    "#         max_angle (float): Final rotation angle, degrees (default 360)\n",
    "#     Returns:\n",
    "#         extrinsics (ndarray): (num_cameras, 3, 4) Sequence of camera extrinsics\n",
    "#     \"\"\"\n",
    "#     angles = np.linspace(initial_angle, max_angle, num_cameras)\n",
    "#     extrinsics = np.zeros((num_cameras, 4, 4))\n",
    "#     for i in range(num_cameras):\n",
    "#         extrinsics[i] = get_object_to_camera_matrix(angles[i], axis, distance)\n",
    "#     return extrinsics\n",
    "# import cv2\n",
    "# def get_object_to_camera_matrix(theta, axis, distance):\n",
    "#     \"\"\"Generate 3x4 object-to-camera matrix that rotates the object around\n",
    "#     the given axis\n",
    "\n",
    "#     Args:\n",
    "#         theta (float): Angle of rotation in radians.\n",
    "#         axis (ndarray): (3,) Axis of rotation\n",
    "#         distance (float): Distance from camera to object\n",
    "#     Returns:\n",
    "#         extrinsics (ndarray): (3, 4) Object-to-camera matrix\n",
    "#     \"\"\"\n",
    "#     theta = theta / 180 * np.pi\n",
    "#     rt4x4 = np.eye(4)\n",
    "#     axis = np.asarray(axis)\n",
    "#     axis = axis / np.linalg.norm(axis)\n",
    "#     # import ipdb; ipdb.set_trace()\n",
    "#     R, _ = cv2.Rodrigues(theta * axis)\n",
    "#     t = np.asarray([0, 0, distance])\n",
    "#     rtmat = np.concatenate((R, t.reshape(3, 1)), axis=1)\n",
    "#     rt4x4[:3, :4] = rtmat\n",
    "#     return rt4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76033016-2d92-4a5d-9e50-3978553e8df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images: 31\n",
      "avg xyz tensor([-0.0218,  0.4226,  0.4587], dtype=torch.float64)\n",
      "# points: 6573\n"
     ]
    }
   ],
   "source": [
    "# Read the COLMAP data.\n",
    "colmap_path = \"/home/cloud/datasets/scan_head\"\n",
    "cameras, images, points_3D = read_model(path=f\"{colmap_path}/dense/sparse\", ext=\".bin\")\n",
    "# Convert camera poses.\n",
    "images = OrderedDict(sorted(images.items()))\n",
    "qvecs = torch.from_numpy(np.stack([image.qvec for image in images.values()]))\n",
    "tvecs = torch.from_numpy(np.stack([image.tvec for image in images.values()]))\n",
    "Rs = camera.quaternion.q_to_R(qvecs)\n",
    "poses = torch.cat([Rs, tvecs[..., None]], dim=-1)  # [N,3,4]\n",
    "print(f\"# images: {len(poses)}\")\n",
    "# Get the sparse 3D points and the colors.\n",
    "xyzs = torch.from_numpy(np.stack([point.xyz for point in points_3D.values()]))\n",
    "print(\"avg xyz\", xyzs.mean(dim=0))\n",
    "rgbs = np.stack([point.rgb for point in points_3D.values()])\n",
    "rgbs = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
    "print(f\"# points: {len(xyzs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cf60ec-fe6a-43ba-9aaf-e3c7afd88208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3575601/2942947300.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rot_poses = torch.tensor(rot_poses[:, :3, :4], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the bounding sphere.\n",
    "json_fname = f\"{colmap_path}/dense/transforms.json\"\n",
    "with open(json_fname) as file:\n",
    "    meta = json.load(file)\n",
    "\n",
    "center = meta[\"sphere_center\"]\n",
    "radius = meta[\"sphere_radius\"]\n",
    "# ------------------------------------------------------------------------------------\n",
    "# These variables can be adjusted to make the bounding sphere fit the region of interest.\n",
    "# The adjusted values can then be set in the config as data.readjust.center and data.readjust.scale\n",
    "readjust_center = np.array([0, 0., -0.2])\n",
    "readjust_scale = 0.6\n",
    "# ------------------------------------------------------------------------------------\n",
    "center += readjust_center\n",
    "radius *= readjust_scale\n",
    "# Make some points to hallucinate a bounding sphere.\n",
    "sphere_points = np.random.randn(100000, 3)\n",
    "sphere_points = sphere_points / np.linalg.norm(sphere_points, axis=-1, keepdims=True)\n",
    "sphere_points = sphere_points * radius + center\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ring_radius = 10\n",
    "# ring_points = np.random.randn(10000, 3)\n",
    "# ring_points[:, 1] = 0\n",
    "\n",
    "# ring_points = ring_points / np.linalg.norm(ring_points, axis=-1, keepdims=True)\n",
    "# ring_points = ring_points * ring_radius\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "axis = [0, 1, 0] / np.sqrt(3)\n",
    "# rot_poses = gen_rot_view(0, 360, 10, 60, axis)\n",
    "import projects.neuralangelo.data\n",
    "# rot_poses = projects.neuralangelo.data.get_rotating_cam(30, axis=axis, distance=10, initial_angle=0, max_angle=360)\n",
    "# M(from meshlab to align object to XYZ axis)\n",
    "\n",
    "\n",
    "\n",
    "def get_cam_pointing_p(cam_pos=[0.0, 0.0, 5.0], point=[0.0, 0.0, 0.0]):\n",
    "    camera_position = torch.tensor([cam_pos])\n",
    "    camera_direction = torch.tensor([point]) - camera_position  # point camera towards the origin\n",
    "    camera_right = torch.cross(torch.tensor([[0.0, 1.0, 0.0]]), camera_direction)\n",
    "\n",
    "    camera_direction = camera_direction / torch.norm(camera_direction, dim=1, keepdim=True)  # normalize direction vector\n",
    "    camera_right = camera_right / torch.norm(camera_right, dim=1, keepdim=True)  # normalize right vector\n",
    "    camera_up = torch.cross(camera_direction, camera_right)\n",
    "\n",
    "    # Compute the camera pose\n",
    "    R = torch.stack([camera_right[0], camera_up[0], camera_direction[0]], dim=1)\n",
    "    # T = -torch.matmul(R, camera_position.transpose(0, 1)).squeeze()\n",
    "    infer_pose = torch.eye(4, dtype=torch.float32)\n",
    "\n",
    "    infer_pose[:3, :3] = R\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    infer_pose[:3, 3] = camera_position[0]\n",
    "    # infer_pose = infer_pose[:3, :]\n",
    "    return infer_pose\n",
    "\n",
    "infer_pose = []\n",
    "\n",
    "for x in range(1, 8):\n",
    "    x = x * -0.5\n",
    "    # infer_pose.append(get_cam_pointing_p(cam_pos=[x * 1., 0., 0.])[:3, :])\n",
    "    # infer_intr.append(template_intr.clone())\n",
    "    # infer_pose.append(get_cam_pointing_p(cam_pos=[0., x * 1., 0.])[:3, :])\n",
    "    # infer_intr.append(template_intr.clone())\n",
    "    p = get_cam_pointing_p(cam_pos=[0., 0., x], point=[0, 0, -1]) # 0.97, 1.75, 4.9\n",
    "    infer_pose.append(p)\n",
    "rot_poses = torch.stack(infer_pose, dim=0)\n",
    "\n",
    "M = np.array([[27,-11.6,4.9,68.4], [12.5,22.7,-15,80], [2.2,15.7,25.5,-152.3],[0,0,0,30]])\n",
    "M = torch.tensor(M / 30, dtype=torch.float64)\n",
    "\n",
    "xyzs_homo = torch.cat([xyzs, torch.ones(xyzs.shape[0], 1)], dim=1)\n",
    "xyzs_homo = (M @ xyzs_homo.T).T\n",
    "xyzs_home = xyzs_homo - xyzs_homo.mean(axis=0)\n",
    "xyzs_concat = torch.concat([xyzs, xyzs_homo[:, :3] / xyzs_homo[:, 3:4]])\n",
    "# xyzs_concat = xyzs_homo[:, :3] / xyzs_homo[:, 3:4]\n",
    "rgbs_concat = np.stack([rgbs, rgbs])\n",
    "# rot_poses = np.matmul(rot_poses, M)\n",
    "rot_poses = torch.tensor(rot_poses[:, :3, :4], dtype=torch.float64)\n",
    "\n",
    "# template_data = torch.load(\"/home/cloud/wxz/neuralangelo/eval_data.pt\")\n",
    "# template_pose = template_data[\"pose\"].to(M.device)\n",
    "# rot_poses = template_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdde170b-4546-4617-9162-a9fcb936347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ee101abf944ba5bd39654973141035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize with K3D.\n",
    "vis_scale = 0.5\n",
    "plot = visualize.k3d_visualize_pose(poses,\n",
    "                                    vis_depth=(0.5 * vis_scale),\n",
    "                                    xyz_length=(0.1 * vis_scale),\n",
    "                                    center_size=(0.05 * vis_scale),\n",
    "                                    xyz_width=(0.02 * vis_scale))\n",
    "# print(rot_poses)\n",
    "# plot = visualize.k3d_visualize_pose(rot_poses,\n",
    "#                                     vis_depth=(0.5 * vis_scale),\n",
    "#                                     xyz_length=(0.1 * vis_scale),\n",
    "#                                     center_size=(0.05 * vis_scale),\n",
    "#                                     xyz_width=(0.02 * vis_scale))\n",
    "plot += k3d.points(xyzs_concat, colors=rgbs_concat, point_size=(0.05 * vis_scale), shader=\"flat\")\n",
    "plot += k3d.points(sphere_points, color=0x4488ff, point_size=0.02, shader=\"flat\")\n",
    "# plot += k3d.points(ring_points, color=0xff2400, point_size=0.02, shader=\"flat\")\n",
    "plot.display()\n",
    "plot.camera_fov = 30.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
